{
    "gpu_a100": {
        "description": "NVIDIA A100 GPU profile for AI inference (INT8), based on public specs and MLPerf data.",
        "mul_lanes": 312000,
        "mul_cols": 1,
        "bit_precision": 8,
        "bit_rate": 1.41,
        "max_parallel_dotprods": 312000,
        "energy_per_mac": {
            "value": 1.5e-12,
            "unit": "J",
            "source": "MLPerf Inference v3.0 + NVIDIA A100 Datasheet (https://www.nvidia.com/en-us/data-center/a100/)"
        },
        "adc_energy_per_conv": {
            "value": 0.0,
            "unit": "J",
            "source": "Not applicable for GPU (purely digital)"
        },
        "dac_energy_per_bit": {
            "value": 0.0,
            "unit": "J",
            "source": "Not applicable for GPU (purely digital)"
        },
        "static_power": {
            "value": 50.0,
            "unit": "W",
            "source": "NVIDIA A100 idle and system support power (MLPerf + datasheet)"
        },
        "area_per_mul_lane": {
            "value": 5e-05,
            "unit": "mm^2",
            "source": "Estimated from dense GPU logic in 7nm process nodes"
        },
        "pca_area": {
            "value": 0.0,
            "unit": "mm^2",
            "source": "Not used in digital GPU"
        },
        "adc_area": {
            "value": 0.0,
            "unit": "mm^2",
            "source": "Not used in digital GPU"
        },
        "waveguide_pitch": {
            "value": 0.0,
            "unit": "mm",
            "source": "Not applicable"
        },
        "reuse_factor": {
            "value": 8,
            "source": "Common assumption in high-throughput matrix scheduling"
        }
    }
}